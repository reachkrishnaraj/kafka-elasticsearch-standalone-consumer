##Kafka ZooKeeper's IP Address/HostName without port
#default value:localhost, if not specified
zookeeper=localhost:2181

##Kafka Broker's IP Address/HostName
#default value:localhost, if not specified
brokerHost=localhost

##Kafka Broker's Port number
#default value:9092, if not specified
brokerPort=9092

##Name of the Kafka Consumer Group
#default value:ESKafkaConsumerClient, if not specified
consumerGroupName=elastic_search_group

##Kafka Topic from which the message has to be processed
#mandatory property, no default value specified.
topic=my_log_topic

#Partition in the Kafka's Topic(defined by 'topic' property) from which the message has to be processed.
#One instance of this consumer read and process from only 1 partition(of the topic)
#default value:0, if not specified
partition=0

##Offset option from where the message fetching should happen in kafka
##Values can be: CUSTOM / OLDEST / LATEST / RESTART.
#CUSTOM:  Message from the specified(defined by 'startOffset' property) offset in Kafka will be read. If 'CUSTOM' is set, then 'startOffset' property has to be set an integer value
#OLDEST:  Messages from oldest available timestamp in kafka will be read
#LATEST:  Messages from latest available timestamp in kafka will be read
#RESTART: Message reading will happen from the Offset where the last cycle of reading by this client has stopped
#Default value:"OLDEST", if not specified
startOffsetFrom=RESTART

#integer value of the offset from where the message processing should happen. Use this property in conjunction with 'startOffsetFrom=CUSTOM'
#mandatory property when 'startOffsetFrom' is set to 'CUSTOM', no default value specified.
startOffset=0

#Full qualified class name for the concrete message handler class factory
#Default value: "org.elasticsearch.kafka.consumer.RawMessageStringHandler", if not specified
#Custom class should be extended from org.elasticsearch.kafka.consumer.MessageHandler class
messageHandlerClass=org.elasticsearch.kafka.consumer.messageHandlers.RawMessageStringHandler

#Fully qualified class name of the custom IndexHandler implementation class
#Default: org.elasticsearch.kafka.consumer.BasicIndexHandler
indexHandlerClass=org.elasticsearch.kafka.consumer.BasicIndexHandler


### DEPRECATED. Provide only the "esHostPortList" and ElasticSearch cluster name in "esClusterName"
esHost=localhost

## Provide the ElasticSearch Host and Port List for all the nodes
esHostPortList=localhost:9300
##Example: esHostPortList=machine_1_ip:9300,machine_2_ip:9300

#Name of the ElasticSearch Cluster. This has to be the elastic search cluster name for which the messages are posted
## Tip: Its not a good idea to use the default name "ElasticSearch" as your cluster name. You have to name your elasticsearch cluster uniquely and configure ##that name here.
esClusterName=TA_POC

### DEPRECATED. Provide only the "esHostPortList" and ElasticSearch cluster name in "esClusterName"
esPort=9300

#IndexName in ElasticSearch to which the processed Message has to be posted/indexed
#Default value is "kafkaConsumerIndex", if not specified
esIndex=kafkaindex1


#IndexType in ElasticSearch to which the processed Message has to be posted/indexed
#Default value is "kafka", if not specified
esIndexType=kafkaLogs


#Percentage of message processing failure tolerance when posting/indexing to ElasticSearch
#Default value is "5", if not specified
# Not used at the moment, can safely ignore
esMsgFailureTolerancePercent=5


#Log property file for the consumer instance. One instance of consumer should have 1 log file.
### It is IMPORTANT to SPECIFY 1 UNIQUE LOG PROPERTY FILE FOR EACH CONSUMER INSTANCE to have logging happen in seperate log file for each consumer instance ###
logPropertyFile=log4jLocal1.properties

##Not used now, reserved for collecting stats
statsdPrefix=
##Not used now, reserved for collecting stats
statsdHost=
##Not used now, reserved for collecting stats
#statsdPort=

##Preferred (integer)Size(bytes) of message to be fetched from Kafka in 1 Fetch call to kafka. 
##Default value is: "31457280(bytes), i.e:(10 * 1024 * 1024 * 3)", if not specified
## Set it to ~4MB and slowly rampup based in your heap memory.
bulkSize=4000000


##Timeout when fetching message from Kafka. 
#Default value is "10000" if not specified
#bulkTimeout=

#Preferred Message Encoding to process the message before posting it to ElasticSearch.
#Default value is "UTF-8" if not specified
#messageEncoding=

##Not used now, can be ignored for now.
# Potential usage: Wanted to handle the Messages which failed either when transforming the message or when indexing/posting the message to ElasticSearch.
#isGuranteedEsPostMode=

## Dry runs will not post to elasticsearch and also wont commit the offser to Kafka
isDryRun=false

##Time in seconds for the consumer to sleep between each round of read and post
consumerSleepTime=10
