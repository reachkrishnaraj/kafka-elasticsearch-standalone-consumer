##Kafka ZooKeeper's IP Address/HostName without port
#default value is "localhost", if not specified
zookeeper=localhost

##Kafka Broker's IP Address/HostName
#default value is "localhost", if not specified
brokerHost=localhost

##Kafka Broker's Port number
#default value is "9092", if not specified
brokerPort=9092

##Name of the Kafka Consumer Group
#mandatory property, no default value specified.
consumerGroupName=ESKafkaConsumerClient

##Kafka Topic from which the message has to be processed
#mandatory property, no default value specified.
topic=KafkaTestTopic

#Partition in the Kafka's Topic(defined by 'topic' property) from which the message has to be processed.
#One instance of this consumer read and process from only 1 partition(of the topic)
#mandatory property, no default value specified.
partition=0

##Offset option from where the message fetching should happen in kafka
##Values can be: CUSTOM|OLDEST|LATEST|RESTART.
#CUSTOM:  Message from the specified(defined by 'startOffset' property) offset in Kafka will be read. If 'CUSTOM' is set, then 'startOffset' property has to be set an integer value
#OLDEST:  Messages from oldest available timestamp in kafka will be read
#LATEST:  Messages from latest available timestamp in kafka will be read
#RESTART: Message reading will happen from the Offset where the last cycle of reading by this client has stopped
#Default value is "OLDEST", if not specified
startOffsetFrom=OLDEST

#integer value of the offset from where the message processing should happen. Use this property in conjunction with 'startOffsetFrom=CUSTOM'
#mandatory property when 'startOffsetFrom' is set to 'CUSTOM', no default value specified.
startOffset=0

#Full qualified class name for the concrete message handler class factory
#Default value is "org.elasticsearch.kafka.consumer.RawMessageStringHandler", if not specified
#Custom class should be extended from org.elasticsearch.kafka.consumer.MessageHandler class
messageHandlerClass=org.elasticsearch.kafka.consumer.messageHandlers.RawMessageStringHandler

#Hostname/IP Address of ElasticSearch. 
#Default value is "localhost", if not specified
esHost=localhost

#Port number of ElasticSearch. 
#Default value is "9300" if not specified
esPort=9300

#IndexName in ElasticSearch to which the processed Message has to be posted/indexed
#Default value is "kafkaConsumerIndex", if not specified
esIndex=kafkaConsumerIndex


#IndexType in ElasticSearch to which the processed Message has to be posted/indexed
#Default value is "kafka", if not specified
esIndexType=kafka


#Percentage of message processing failure tolerance when posting/indexing to ElasticSearch
#Default value is "5", if not specified
esMsgFailureTolerancePercent=5


#Name of the ElasticSearch Cluster. Not mandatory, can be ignored
#esClusterName=

#Log property file for the consumer instance. One instance of consumer should have 1 log file.
### It is IMPORTANT to SPECIFY 1 UNIQUE LOG PROPERTY FILE FOR EACH CONSUMER INSTANCE to have logging happen in separate log file for each consumer instance ###
###### Log Property File NEEDS TO BE IN "config" folder. DONT MENTION PATH, JUST FILE NAME ###### 
logPropertyFile=log4jConsumerInstance_1.properties

##Not used now, reserved for collecting stats
statsdPrefix=
##Not used now, reserved for collecting stats
statsdHost=
##Not used now, reserved for collecting stats
#statsdPort=

##Preferred (integer)Size(bytes) of message to be fetched from Kafka in 1 Fetch call to kafka. 
##Default value is: "31457280(bytes), i.e:(10 * 1024 * 1024 * 3)", if not specified
#bulkSize=


##Timeout when fetching message from Kafka. 
#Default value is "10000" if not specified
#bulkTimeout=

#Preferred Message Encoding to process the message before posting it to ElasticSearch.
#Default value is "UTF-8" if not specified
#messageEncoding=

##Not used now, can be ignored for now.
# Potential usage: Wanted to handle the Messages which failed either when transforming the message or when indexing/posting the message to ElasticSearch.
#isGuranteedEsPostMode=